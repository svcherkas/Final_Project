{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnNAOfZy4ni0",
        "outputId": "a016426c-761d-4f48-b8cc-c0f439a8714b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: telebot in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (0.0.5)\n",
            "Requirement already satisfied: pyTelegramBotAPI in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from telebot) (4.14.0)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from telebot) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->telebot) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->telebot) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->telebot) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->telebot) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install telebot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGc7Y5Jj5BN0",
        "outputId": "81d64abb-773c-4cbb-c887-9fabad3e58d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (3.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4AxOu-6aVKp",
        "outputId": "d6b34382-480e-4931-d8f7-0773ee66e172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sVRQAfUnEX3",
        "outputId": "477bbd03-f1fc-45ae-ab39-8c7c99af6f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (0.0.53)\n",
            "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from sacremoses) (2023.10.3)\n",
            "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from sacremoses) (4.66.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from click->sacremoses) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install sacremoses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNukh4k_I4Ir",
        "outputId": "28605cab-80b1-4f94-8b02-7b0197349ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymystem3 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (0.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from pymystem3) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->pymystem3) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->pymystem3) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->pymystem3) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\bot\\lib\\site-packages (from requests->pymystem3) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pymystem3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yR5SWXrZ4nly"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\envs\\bot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import telebot\n",
        "from telebot import types\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import ast\n",
        "import json\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pymystem3 import Mystem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6vw06-N519_",
        "outputId": "b548302d-5478-498d-d65e-15b34a6f578f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 618ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 58ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ru.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Button 'write' was pressed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 15:19:25,551 (__init__.py:966 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
            "2023-11-07 15:19:25,552 (__init__.py:968 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n"
          ]
        }
      ],
      "source": [
        "token='6600479591:AAGLrNOY9T-wqLLm0pEoE6AvLGpLnJFf2GQ'\n",
        "bot=telebot.TeleBot(token)\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start_message(message):\n",
        "  global recognized_items\n",
        "  recognized_items = []\n",
        "  last_button_pressed = None\n",
        "  bot.send_message(message.chat.id,\"Добро пожаловать! Я - твой помощник на кухне. С моей помощью ты сможешь не только распознать продукты по фотографии, но и найти уникальные рецепты, которые подойдут именно для этих продуктов. Давай начнем! Просто отправь фото продукта\")\n",
        "\n",
        "# Создайте глобальный список для хранения распознанных фруктов и овощей\n",
        "recognized_items = []\n",
        "\n",
        "#Загружает изображение с заданным размером, преобразует изображение в массив numpy, \n",
        "#добавляет дополнительное измерение к массиву, нормализует значения пикселей \n",
        "def get_img_array(img_path, size):\n",
        "   img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "   array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "   array = np.expand_dims(array, axis=0)\n",
        "   return array/255\n",
        "\n",
        "#Загружает предварительно обученную модель из файла\n",
        "model = load_model('my_classification_model.h5')\n",
        "\n",
        "#Загружает изображение и преобразует его в массив с размерами (224, 224) с помощью функции get_img_array.\n",
        "def recognize_image(image_path):\n",
        "    img = get_img_array(image_path, (224, 224))\n",
        "    #Определяет метки классов для различных видов продуктов.\n",
        "    class_labels = ['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage',\n",
        "                   'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn',\n",
        "                   'cucumber', 'egg', 'plant garlic', 'ginger', 'grapes',\n",
        "                   'jalepeno', 'kiwi', 'lemon', 'lettuce', 'mango',\n",
        "                   'onion', 'orange', 'paprika', 'pear', 'peas',\n",
        "                   'pineapple', 'pomegranate', 'potato', 'raddish', 'soy beans',\n",
        "                   'spinach', 'sweetcor', 'sweetpotato', 'tomato', 'turnip',\n",
        "                   'watermelon']\n",
        "    #Использует модель для предсказания класса объекта на изображении.\n",
        "    preds = model.predict(img)\n",
        "    pred_class = np.argmax(preds[0])\n",
        "    #Использует модель перевода для перевода названия класса с английского на русский.\n",
        "    translator = pipeline(\"translation_en_to_ru\", model=\"Helsinki-NLP/opus-mt-en-ru\")\n",
        "\n",
        "    # Переведите название на русский язык\n",
        "    results = translator([class_labels[pred_class]])\n",
        "    pred_class_russian = results[0]['translation_text']\n",
        "\n",
        "    # Добавьте распознанный элемент в список\n",
        "    recognized_items.append(pred_class_russian)\n",
        "\n",
        "    return f\"Продукт на фото: {pred_class_russian}\"\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def handle_docs_photo(message):\n",
        "    #Функция get_file вызывается с идентификатором файла последней фотографии в сообщении. Это возвращает информацию о файле.\n",
        "    file_info = bot.get_file(message.photo[len(message.photo)-1].file_id)\n",
        "    #Функция download_file вызывается с путем к файлу, чтобы загрузить файл.\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "\n",
        "    #Файл сохраняется на диск\n",
        "    with open('image.jpg', 'wb') as new_file:\n",
        "      new_file.write(downloaded_file)\n",
        "\n",
        "    # Предсказание класса изображения\n",
        "    prediction = recognize_image('image.jpg')\n",
        "\n",
        "    # Отправка предсказания пользователю\n",
        "    bot.reply_to(message, prediction)\n",
        "\n",
        "    # Создание кнопок для первого этапа\n",
        "    markup = types.InlineKeyboardMarkup()\n",
        "    item1 = types.InlineKeyboardButton(\"Загрузить еще фото\", callback_data='load')\n",
        "    item2 = types.InlineKeyboardButton(\"Нет\", callback_data='no')\n",
        "    markup.add(item1, item2)\n",
        "\n",
        "    bot.send_message(message.chat.id, 'Вы хотите загрузить еще фото?', reply_markup=markup)\n",
        "\n",
        "last_button_pressed = None\n",
        "\n",
        "\n",
        "@bot.callback_query_handler(func=lambda call: True)\n",
        "def callback_inline(call):\n",
        "    global recognized_items, last_button_pressed\n",
        "    try:\n",
        "        if call.message:\n",
        "            if call.data == 'load':\n",
        "                # Если пользователь хочет загрузить еще фото, отправляем ему сообщение и продолжаем ждать новых фото\n",
        "                bot.send_message(call.message.chat.id, 'Пожалуйста, загрузи фото продукта.')\n",
        "            elif call.data == 'no':\n",
        "                # Если пользователь не хочет загрузить еще фото, выводим список и переходим к следующему этапу\n",
        "                bot.send_message(call.message.chat.id, 'Список распознанных ингредиентов')\n",
        "                bot.send_message(call.message.chat.id, ', '.join(recognized_items))\n",
        "\n",
        "                markup = types.InlineKeyboardMarkup()\n",
        "                item1 = types.InlineKeyboardButton(\"Добавь еще ингредиенты в этот список\", callback_data='add')\n",
        "                item2 = types.InlineKeyboardButton(\"Распознанный список ингредиентов верен\", callback_data='right')\n",
        "                item3 = types.InlineKeyboardButton(\"Напиши свой список ингредиентов\", callback_data='write')\n",
        "                markup.add(item1)\n",
        "                markup.add(item2)\n",
        "                markup.add(item3)\n",
        "\n",
        "                bot.send_message(call.message.chat.id, 'Далее можно откорректировать список либо создать свой список ингредиентов', reply_markup=markup)\n",
        "\n",
        "            elif call.data == 'add':\n",
        "                # Если пользователь хочет добавить ингредиенты в список, отправляем ему сообщение и ждем новых ингредиентов\n",
        "                bot.send_message(call.message.chat.id, 'Пожалуйста, напиши ингредиенты, которые ты хочешь добавить в список.')\n",
        "                last_button_pressed = 'add'\n",
        "\n",
        "            elif call.data == 'right':\n",
        "                # Отправьте список распознанных ингредиентов пользователю\n",
        "                bot.send_message(call.message.chat.id, 'Список распознанных ингредиентов:')\n",
        "                bot.send_message(call.message.chat.id, ', '.join(recognized_items))\n",
        "\n",
        "                # Вызов функции, которая возвращает топ-5 блюд с наибольшим количеством совпадающих ингредиентов\n",
        "                file_path = './povarenok.csv'\n",
        "                top_5_dishes = top_5_dishes_with_matching_ingredients(file_path, recognized_items)\n",
        "\n",
        "                # Создайте кнопки для каждого блюда и отправьте их пользователю\n",
        "                markup = types.InlineKeyboardMarkup()\n",
        "                for index, row in top_5_dishes.iterrows():\n",
        "                    item = types.InlineKeyboardButton(row['name'], url=row['url'])\n",
        "                    markup.add(item)\n",
        "\n",
        "                bot.send_message(call.message.chat.id, 'Рекомендуемые блюда:', reply_markup=markup)\n",
        "                bot.send_message(call.message.chat.id, 'Хочешь начать заново?   Нажми  /start .')\n",
        "\n",
        "            elif call.data == 'write':\n",
        "                print(\"Button 'write' was pressed\")\n",
        "                # Если пользователь хочет написать свой список, обнуляем список recognized_items и ждем новый список\n",
        "                recognized_items = []\n",
        "                bot.send_message(call.message.chat.id, 'Пожалуйста, напиши свой список ингредиентов.')\n",
        "                last_button_pressed = 'write'\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "        #print(e)\n",
        "\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def handle_message(message):\n",
        "    global recognized_items, last_button_pressed\n",
        "    if last_button_pressed == 'add':\n",
        "        # Если последней нажатой кнопкой была \"add\", добавляем сообщение пользователя в список\n",
        "        recognized_items.append(message.text)\n",
        "        bot.send_message(message.chat.id, ', '.join(recognized_items))\n",
        "\n",
        "        file_path = './povarenok.csv'\n",
        "        top_5_dishes = top_5_dishes_with_matching_ingredients(file_path, recognized_items)\n",
        "\n",
        "        # Создайте кнопки для каждого блюда\n",
        "        markup = types.InlineKeyboardMarkup()\n",
        "        for index, row in top_5_dishes.iterrows():\n",
        "            item = types.InlineKeyboardButton(row['name'], url=row['url'])\n",
        "            markup.add(item)\n",
        "\n",
        "        bot.send_message(message.chat.id, 'Рекомендуемые блюда:', reply_markup=markup)\n",
        "        bot.send_message(message.chat.id, 'Хочешь начать заново?   Нажми  /start .')\n",
        "\n",
        "    elif last_button_pressed == 'right':\n",
        "        # Если последней нажатой кнопкой была \"right\"\n",
        "        bot.send_message(message.chat.id, 'Список распознанных ингредиентов')\n",
        "        recognized_items = message.text.split(',')\n",
        "        bot.send_message(message.chat.id, ', '.join(recognized_items))\n",
        "\n",
        "        file_path = './povarenok.csv'\n",
        "        top_5_dishes = top_5_dishes_with_matching_ingredients(file_path, recognized_items)\n",
        "\n",
        "        # Создайте кнопки для каждого блюда\n",
        "        markup = types.InlineKeyboardMarkup()\n",
        "        for index, row in top_5_dishes.iterrows():\n",
        "            item = types.InlineKeyboardButton(row['name'], url=row['url'])\n",
        "            markup.add(item)\n",
        "\n",
        "        bot.send_message(message.chat.id, 'Рекомендуемые блюда:', reply_markup=markup)\n",
        "        bot.send_message(message.chat.id, 'Хочешь начать заново?   Нажми  /start .')\n",
        "\n",
        "    elif last_button_pressed == 'write':\n",
        "        # Если последней нажатой кнопкой была \"write\", заменяем список сообщением пользователя\n",
        "        recognized_items = [item.strip() for sublist in message.text.split(',') for item in sublist.split()]\n",
        "        bot.send_message(message.chat.id, ', '.join(recognized_items))\n",
        "\n",
        "        file_path = './povarenok.csv'\n",
        "        top_5_dishes = top_5_dishes_with_matching_ingredients(file_path, recognized_items)\n",
        "\n",
        "        # Создайте кнопки для каждого блюда\n",
        "        markup = types.InlineKeyboardMarkup()\n",
        "        for index, row in top_5_dishes.iterrows():\n",
        "            item = types.InlineKeyboardButton(row['name'], url=row['url'])\n",
        "            markup.add(item)\n",
        "\n",
        "        bot.send_message(message.chat.id, 'Рекомендуемые блюда:', reply_markup=markup)\n",
        "        bot.send_message(message.chat.id, 'Хочешь начать заново?   Нажми  /start .')\n",
        "\n",
        "        last_button_pressed = None\n",
        "\n",
        "from pymystem3 import Mystem\n",
        "def top_5_dishes_with_matching_ingredients(file_path, recognized_items):\n",
        "    # Загрузите данные из файла Excel\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Создайте объект стеммера для русского языка\n",
        "    mystem = Mystem()\n",
        "    # Замена пропущенных значений на пустой словарь\n",
        "    df['ingredients'] = df['ingredients'].fillna('{}')\n",
        "    # Преобразование строк в словари\n",
        "    df['ingredients'] = df['ingredients'].apply(ast.literal_eval)\n",
        "    # Создание нового столбца с ключами словаря\n",
        "    df['keys'] = df['ingredients'].apply(lambda x: ', '.join(list(x.keys())))\n",
        "    df = df.drop('ingredients', axis=1, inplace=False)\n",
        "    # Преобразуйте все строки в столбце 'keys' к нижнему регистру\n",
        "    df['keys'] = df['keys'].str.lower()\n",
        "    recognized_items = [mystem.lemmatize(ingredient.lower())[0] for ingredient in recognized_items]\n",
        "    # Создайте новый столбец, который будет содержать количество совпадающих продуктов в каждой строке\n",
        "    df['matching_count'] = df['keys'].apply(lambda x: sum(1 for ingredient in recognized_items if ingredient in x))\n",
        "    # Отсортируйте таблицу по столбцу 'matching_count' в убывающем порядке\n",
        "    df = df.sort_values(by='matching_count', ascending=False)\n",
        "    # Выведите первые 5 блюд с наибольшим количеством совпадающих продуктов\n",
        "    top_5_dishes = df.head(5)\n",
        "    return top_5_dishes\n",
        "\n",
        "\n",
        "bot.infinity_polling()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBLK7weIDwWu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
